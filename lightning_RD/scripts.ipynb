{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7046dc12-8976-4f6a-83ce-6e9e8b53369a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==0.12.0\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting aiohttp==3.7.4.post0\n",
      "  Using cached aiohttp-3.7.4.post0-cp38-cp38-manylinux2014_x86_64.whl (1.5 MB)\n",
      "Collecting async-timeout==3.0.1\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting attrs==21.2.0\n",
      "  Using cached attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting cachetools==4.2.2\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting certifi==2021.5.30\n",
      "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting chardet==4.0.0\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting click==8.0.1\n",
      "  Using cached click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting filelock==3.0.12\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting fsspec==2021.6.0\n",
      "  Using cached fsspec-2021.6.0-py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.18.2)\n",
      "Collecting google-auth==1.30.2\n",
      "  Using cached google_auth-1.30.2-py2.py3-none-any.whl (146 kB)\n",
      "Collecting google-auth-oauthlib==0.4.4\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio==1.38.0\n",
      "  Using cached grpcio-1.38.0-cp38-cp38-manylinux2014_x86_64.whl (4.2 MB)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Collecting idna==2.10\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting joblib==1.0.1\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting Markdown==3.3.4\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting multidict==5.1.0\n",
      "  Using cached multidict-5.1.0-cp38-cp38-manylinux2014_x86_64.whl (159 kB)\n",
      "Collecting numpy==1.20.3\n",
      "  Using cached numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
      "Collecting oauthlib==3.1.1\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting packaging==20.9\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting protobuf==3.17.3\n",
      "  Using cached protobuf-3.17.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 24)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 25)) (0.2.8)\n",
      "Collecting pyDeprecate==0.3.0\n",
      "  Using cached pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting pytorch-lightning==1.3.4\n",
      "  Using cached pytorch_lightning-1.3.4-py3-none-any.whl (806 kB)\n",
      "Collecting PyYAML==5.4.1\n",
      "  Using cached PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "Collecting regex==2021.4.4\n",
      "  Using cached regex-2021.4.4-cp38-cp38-manylinux2014_x86_64.whl (733 kB)\n",
      "Collecting requests==2.25.1\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting requests-oauthlib==1.3.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting rsa==4.7.2\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting sacremoses==0.0.45\n",
      "  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (1.16.0)\n",
      "Collecting tensorboard==2.4.1\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting tensorboard-plugin-wit==1.8.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting tokenizers==0.10.3\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting torchmetrics==0.3.2\n",
      "  Using cached torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n",
      "Collecting tqdm==4.61.0\n",
      "  Using cached tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting transformers==4.6.1\n",
      "  Using cached transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "Collecting typing-extensions==3.10.0.0\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting urllib3==1.26.5\n",
      "  Using cached urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "Collecting Werkzeug==2.0.1\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting yarl==1.6.3\n",
      "  Using cached yarl-1.6.3-cp38-cp38-manylinux2014_x86_64.whl (324 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.8/dist-packages (from google-auth==1.30.2->-r requirements.txt (line 12)) (61.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.3.4->-r requirements.txt (line 28)) (2022.7.1)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.3.4->-r requirements.txt (line 28)) (1.12.0.dev20220327+cu113)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.4.1->-r requirements.txt (line 36)) (0.37.1)\n",
      "Collecting fsspec[http]>=2021.4.0\n",
      "  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.2/141.2 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Using cached fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "  Using cached fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "  Using cached fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "  Using cached fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "  Using cached fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "  Using cached fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "  Using cached fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
      "  Using cached fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
      "  Using cached fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
      "  Using cached fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
      "  Using cached fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "  Using cached fsspec-2021.6.1-py3-none-any.whl (115 kB)\n",
      "Installing collected packages: typing-extensions, tokenizers, tensorboard-plugin-wit, regex, filelock, certifi, Werkzeug, urllib3, tqdm, rsa, PyYAML, pyparsing, pyDeprecate, protobuf, oauthlib, numpy, multidict, Markdown, joblib, idna, grpcio, fsspec, click, chardet, cachetools, attrs, async-timeout, absl-py, yarl, sacremoses, requests, packaging, google-auth, torchmetrics, requests-oauthlib, huggingface-hub, aiohttp, transformers, google-auth-oauthlib, tensorboard, pytorch-lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.1.1\n",
      "    Uninstalling typing_extensions-4.1.1:\n",
      "      Successfully uninstalled typing_extensions-4.1.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: tensorboard-plugin-wit\n",
      "    Found existing installation: tensorboard-plugin-wit 1.8.1\n",
      "    Uninstalling tensorboard-plugin-wit-1.8.1:\n",
      "      Successfully uninstalled tensorboard-plugin-wit-1.8.1\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2022.7.25\n",
      "    Uninstalling regex-2022.7.25:\n",
      "      Successfully uninstalled regex-2022.7.25\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.6.0\n",
      "    Uninstalling filelock-3.6.0:\n",
      "      Successfully uninstalled filelock-3.6.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.2.2\n",
      "    Uninstalling Werkzeug-2.2.2:\n",
      "      Successfully uninstalled Werkzeug-2.2.2\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.63.1\n",
      "    Uninstalling tqdm-4.63.1:\n",
      "      Successfully uninstalled tqdm-4.63.1\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.8\n",
      "    Uninstalling rsa-4.8:\n",
      "      Successfully uninstalled rsa-4.8\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.7\n",
      "    Uninstalling pyparsing-3.0.7:\n",
      "      Successfully uninstalled pyparsing-3.0.7\n",
      "  Attempting uninstall: pyDeprecate\n",
      "    Found existing installation: pyDeprecate 0.3.2\n",
      "    Uninstalling pyDeprecate-0.3.2:\n",
      "      Successfully uninstalled pyDeprecate-0.3.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.0\n",
      "    Uninstalling oauthlib-3.2.0:\n",
      "      Successfully uninstalled oauthlib-3.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.2\n",
      "    Uninstalling multidict-6.0.2:\n",
      "      Successfully uninstalled multidict-6.0.2\n",
      "  Attempting uninstall: Markdown\n",
      "    Found existing installation: Markdown 3.3.6\n",
      "    Uninstalling Markdown-3.3.6:\n",
      "      Successfully uninstalled Markdown-3.3.6\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.44.0\n",
      "    Uninstalling grpcio-1.44.0:\n",
      "      Successfully uninstalled grpcio-1.44.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.0.0\n",
      "    Uninstalling cachetools-5.0.0:\n",
      "      Successfully uninstalled cachetools-5.0.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.4.0\n",
      "    Uninstalling attrs-21.4.0:\n",
      "      Successfully uninstalled attrs-21.4.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 4.0.2\n",
      "    Uninstalling async-timeout-4.0.2:\n",
      "      Successfully uninstalled async-timeout-4.0.2\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.0.0\n",
      "    Uninstalling absl-py-1.0.0:\n",
      "      Successfully uninstalled absl-py-1.0.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.8.1\n",
      "    Uninstalling yarl-1.8.1:\n",
      "      Successfully uninstalled yarl-1.8.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.6.2\n",
      "    Uninstalling google-auth-2.6.2:\n",
      "      Successfully uninstalled google-auth-2.6.2\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 0.9.3\n",
      "    Uninstalling torchmetrics-0.9.3:\n",
      "      Successfully uninstalled torchmetrics-0.9.3\n",
      "  Attempting uninstall: requests-oauthlib\n",
      "    Found existing installation: requests-oauthlib 1.3.1\n",
      "    Uninstalling requests-oauthlib-1.3.1:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.8.1\n",
      "    Uninstalling huggingface-hub-0.8.1:\n",
      "      Successfully uninstalled huggingface-hub-0.8.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.1\n",
      "    Uninstalling aiohttp-3.8.1:\n",
      "      Successfully uninstalled aiohttp-3.8.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.0\n",
      "    Uninstalling transformers-4.21.0:\n",
      "      Successfully uninstalled transformers-4.21.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.9.1\n",
      "    Uninstalling tensorboard-2.9.1:\n",
      "      Successfully uninstalled tensorboard-2.9.1\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.7.0\n",
      "    Uninstalling pytorch-lightning-1.7.0:\n",
      "      Successfully uninstalled pytorch-lightning-1.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.4.1 which is incompatible.\n",
      "onnxruntime-gpu 1.11.0 requires numpy>=1.21.0, but you have numpy 1.20.3 which is incompatible.\n",
      "flask 2.2.2 requires Werkzeug>=2.2.2, but you have werkzeug 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Markdown-3.3.4 PyYAML-5.4.1 Werkzeug-2.0.1 absl-py-0.12.0 aiohttp-3.7.4.post0 async-timeout-3.0.1 attrs-21.2.0 cachetools-4.2.2 certifi-2021.5.30 chardet-4.0.0 click-8.0.1 filelock-3.0.12 fsspec-2021.6.0 google-auth-1.30.2 google-auth-oauthlib-0.4.4 grpcio-1.38.0 huggingface-hub-0.0.8 idna-2.10 joblib-1.0.1 multidict-5.1.0 numpy-1.20.3 oauthlib-3.1.1 packaging-20.9 protobuf-3.17.3 pyDeprecate-0.3.0 pyparsing-2.4.7 pytorch-lightning-1.3.4 regex-2021.4.4 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 sacremoses-0.0.45 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tokenizers-0.10.3 torchmetrics-0.3.2 tqdm-4.61.0 transformers-4.6.1 typing-extensions-3.10.0.0 urllib3-1.26.5 yarl-1.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8c9c893f-ce78-4c91-84d3-a98d1364da04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: You requested multiple GPUs but did not specify a backend, e.g. `Trainer(accelerator=\"dp\"|\"ddp\"|\"ddp2\")`. Setting `accelerator=\"ddp_spawn\"` for you.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "initializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | bert_mlm | BertForMaskedLM | 110 M \n",
      "---------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.604   Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s]/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: accelerator=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: num_workers>0, persistent_workers=False, and accelerator=ddp_spawn may result in data loading bottlenecks. Consider setting persistent_workers=True (this is a limitation of Python .spawn() and PyTorch)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   0%|                                           | 0/47 [00:00<?, ?it/s][W reducer.cpp:1263] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1263] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  85%|▊| 40/47 [00:08<00:01,  4.46it/s, loss=1.06, v_num=2, val_loss=9.1\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 47/47 [00:09<00:00,  5.18it/s, loss=1.06, v_num=2, val_loss=0.8\u001b[A\n",
      "                                                                                \u001b[A/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 1:  83%|▊| 39/47 [00:07<00:01,  4.94it/s, loss=0.143, v_num=2, val_loss=0.^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 62, in <module>\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "    main()\n",
      "  File \"train.py\", line 58, in main\n",
      "    trainer.fit(model)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 458, in fit\n",
      "    self._run(model)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 756, in _run\n",
      "    self.dispatch()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py\", line 797, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: cleaning up ddp environment...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/training_type/ddp_spawn.py\", line 122, in start_training\n",
      "    mp.spawn(self.new_process, **self.mp_spawn_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 109, in join\n",
      "    ready = multiprocessing.connection.wait(\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --k 5 --max_epochs 10 --batch_size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ee299854-2133-40de-8cc0-17061bce82d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "### desc: 죄와 벌- 도스토옙스키,살해한다)를 살해하고 돈을 훔치며 방황하다 결국 사랑과 신 앞에 자신의 과오를 뉘우치고 새삶을 찾는다는 다분히 개과천선적인 이야기이다. 하지만 이 소설을 내내 편히 읽으면서 자연스럽게 파악하게 되는 것이 있는데 바로 라스콜리니코프와 대척점에... ###\n",
      "0: ('개과천선', 0.999996542930603)\n",
      "1: ('수어지교', 3.1489112188864965e-06)\n",
      "2: ('함흥차사', 1.2230759693920845e-07)\n",
      "3: ('군계일학', 5.1923993993341355e-08)\n",
      "4: ('백전백승', 4.173730161483036e-08)\n",
      "5: ('조령모개', 3.407961912671453e-08)\n",
      "6: ('마부작침', 2.771530560607971e-08)\n",
      "7: ('독서망양', 1.782189684718105e-08)\n",
      "8: ('대기만성', 6.924367745853033e-09)\n",
      "9: ('다다익선', 3.5056400005117894e-09)\n"
     ]
    }
   ],
   "source": [
    "!python3 infer.py --desc '죄와 벌- 도스토옙스키,살해한다)를 살해하고 돈을 훔치며 방황하다 결국 사랑과 신 앞에 자신의 과오를 뉘우치고 새삶을 찾는다는 다분히 개과천선적인 이야기이다. 하지만 이 소설을 내내 편히 읽으면서 자연스럽게 파악하게 되는 것이 있는데 바로 라스콜리니코프와 대척점에...' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b41b63-c360-4080-9cca-496b2dd57f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
